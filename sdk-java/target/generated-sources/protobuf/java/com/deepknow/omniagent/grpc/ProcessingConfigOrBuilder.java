// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: multimodal.proto

// Protobuf Java Version: 3.25.1
package com.deepknow.omniagent.grpc;

public interface ProcessingConfigOrBuilder extends
    // @@protoc_insertion_point(interface_extends:omniagent.ProcessingConfig)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <pre>
   * STT 配置
   * </pre>
   *
   * <code>string stt_provider = 1;</code>
   * @return The sttProvider.
   */
  java.lang.String getSttProvider();
  /**
   * <pre>
   * STT 配置
   * </pre>
   *
   * <code>string stt_provider = 1;</code>
   * @return The bytes for sttProvider.
   */
  com.google.protobuf.ByteString
      getSttProviderBytes();

  /**
   * <pre>
   * STT 模型
   * </pre>
   *
   * <code>string stt_model = 2;</code>
   * @return The sttModel.
   */
  java.lang.String getSttModel();
  /**
   * <pre>
   * STT 模型
   * </pre>
   *
   * <code>string stt_model = 2;</code>
   * @return The bytes for sttModel.
   */
  com.google.protobuf.ByteString
      getSttModelBytes();

  /**
   * <pre>
   * 语言: zh-CN, en-US
   * </pre>
   *
   * <code>string language = 3;</code>
   * @return The language.
   */
  java.lang.String getLanguage();
  /**
   * <pre>
   * 语言: zh-CN, en-US
   * </pre>
   *
   * <code>string language = 3;</code>
   * @return The bytes for language.
   */
  com.google.protobuf.ByteString
      getLanguageBytes();

  /**
   * <pre>
   * LLM 配置
   * </pre>
   *
   * <code>string llm_provider = 4;</code>
   * @return The llmProvider.
   */
  java.lang.String getLlmProvider();
  /**
   * <pre>
   * LLM 配置
   * </pre>
   *
   * <code>string llm_provider = 4;</code>
   * @return The bytes for llmProvider.
   */
  com.google.protobuf.ByteString
      getLlmProviderBytes();

  /**
   * <pre>
   * LLM 模型: qwen-turbo, gpt-4
   * </pre>
   *
   * <code>string llm_model = 5;</code>
   * @return The llmModel.
   */
  java.lang.String getLlmModel();
  /**
   * <pre>
   * LLM 模型: qwen-turbo, gpt-4
   * </pre>
   *
   * <code>string llm_model = 5;</code>
   * @return The bytes for llmModel.
   */
  com.google.protobuf.ByteString
      getLlmModelBytes();

  /**
   * <pre>
   * 温度
   * </pre>
   *
   * <code>float temperature = 6;</code>
   * @return The temperature.
   */
  float getTemperature();

  /**
   * <pre>
   * 最大 token
   * </pre>
   *
   * <code>int32 max_tokens = 7;</code>
   * @return The maxTokens.
   */
  int getMaxTokens();

  /**
   * <pre>
   * 系统提示词
   * </pre>
   *
   * <code>string system_prompt = 8;</code>
   * @return The systemPrompt.
   */
  java.lang.String getSystemPrompt();
  /**
   * <pre>
   * 系统提示词
   * </pre>
   *
   * <code>string system_prompt = 8;</code>
   * @return The bytes for systemPrompt.
   */
  com.google.protobuf.ByteString
      getSystemPromptBytes();

  /**
   * <pre>
   * 输出配置
   * </pre>
   *
   * <code>bool enable_tts = 9;</code>
   * @return The enableTts.
   */
  boolean getEnableTts();

  /**
   * <pre>
   * TTS 提供商（预留）
   * </pre>
   *
   * <code>string tts_provider = 10;</code>
   * @return The ttsProvider.
   */
  java.lang.String getTtsProvider();
  /**
   * <pre>
   * TTS 提供商（预留）
   * </pre>
   *
   * <code>string tts_provider = 10;</code>
   * @return The bytes for ttsProvider.
   */
  com.google.protobuf.ByteString
      getTtsProviderBytes();

  /**
   * <pre>
   * TTS 音色（预留）
   * </pre>
   *
   * <code>string tts_voice = 11;</code>
   * @return The ttsVoice.
   */
  java.lang.String getTtsVoice();
  /**
   * <pre>
   * TTS 音色（预留）
   * </pre>
   *
   * <code>string tts_voice = 11;</code>
   * @return The bytes for ttsVoice.
   */
  com.google.protobuf.ByteString
      getTtsVoiceBytes();
}
